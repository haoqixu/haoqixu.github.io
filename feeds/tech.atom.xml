<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>~xu0o0 - Tech</title><link href="http://blog.xu0o0.me/" rel="alternate"></link><link href="http://blog.xu0o0.me/feeds/tech.atom.xml" rel="self"></link><id>http://blog.xu0o0.me/</id><updated>2017-12-28T00:00:00+08:00</updated><entry><title>【译】系统管理 101：补丁管理</title><link href="http://blog.xu0o0.me/posts/2017/12/sysadmin-101-patch-management.html" rel="alternate"></link><published>2017-12-28T00:00:00+08:00</published><updated>2017-12-28T00:00:00+08:00</updated><author><name>xu0o0</name></author><id>tag:blog.xu0o0.me,2017-12-28:/posts/2017/12/sysadmin-101-patch-management.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;原文链接：&lt;a href="https://www.linuxjournal.com/content/sysadmin-101-patch-management"&gt;https://www.linuxjournal.com/content/sysadmin-101-patch-management&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原文作者：&lt;a href="https://www.linuxjournal.com/users/kyle-rankin"&gt;Kyle Rankin&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;校对：&lt;a href="https://linux.cn/article-8811-1.html"&gt;Linux.CN&lt;/a&gt; 的 &lt;a href="https://github.com/wxy"&gt;wxy 前辈&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发布平台：&lt;a href="https://linux.cn/article-9179-1.html"&gt;Linux中国&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;就在之前几篇文章，我开始了“系统管理 101”系列文章，用来记录现今许多初级系统管理员、DevOps 工程师或者“全栈”开发者可能不曾接触过的一些系统管理方面的基本知识。按照我原本的设想，该系列文章已经是完结了的。然而后来 WannaCry 恶意软件出现，并在补丁管理不善的 Windows 主机网络间爆发。我能想象到那些仍然深陷 2000 年代 Linux 与 Windows 争论的读者听到这个消息可能已经面露优越的微笑。&lt;/p&gt;
&lt;p&gt;我之所以这么快就决定再次继续“系统管理 101”文章系列，是因为我意识到在补丁管理方面一些 Linux 系统管理员和 …&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;原文链接：&lt;a href="https://www.linuxjournal.com/content/sysadmin-101-patch-management"&gt;https://www.linuxjournal.com/content/sysadmin-101-patch-management&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原文作者：&lt;a href="https://www.linuxjournal.com/users/kyle-rankin"&gt;Kyle Rankin&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;校对：&lt;a href="https://linux.cn/article-8811-1.html"&gt;Linux.CN&lt;/a&gt; 的 &lt;a href="https://github.com/wxy"&gt;wxy 前辈&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发布平台：&lt;a href="https://linux.cn/article-9179-1.html"&gt;Linux中国&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;就在之前几篇文章，我开始了“系统管理 101”系列文章，用来记录现今许多初级系统管理员、DevOps 工程师或者“全栈”开发者可能不曾接触过的一些系统管理方面的基本知识。按照我原本的设想，该系列文章已经是完结了的。然而后来 WannaCry 恶意软件出现，并在补丁管理不善的 Windows 主机网络间爆发。我能想象到那些仍然深陷 2000 年代 Linux 与 Windows 争论的读者听到这个消息可能已经面露优越的微笑。&lt;/p&gt;
&lt;p&gt;我之所以这么快就决定再次继续“系统管理 101”文章系列，是因为我意识到在补丁管理方面一些 Linux 系统管理员和 Windows 系统管理员没有差别。实话说，在一些方面甚至做的更差（特别是以持续运行时间为荣）。所以，这篇文章会涉及 Linux 下补丁管理的基础概念，包括良好的补丁管理该是怎样的，你可能会用到的一些相关工具，以及整个补丁安装过程是如何进行的。&lt;/p&gt;
&lt;h3 id="_1"&gt;什么是补丁管理？&lt;/h3&gt;
&lt;p&gt;我所说的补丁管理，是指你部署用于升级服务器上软件的系统，不仅仅是把软件更新到最新最好的前沿版本。即使是像 Debian 这样为了“稳定性”持续保持某一特定版本软件的保守派发行版，也会时常发布升级补丁用于修补错误和安全漏洞。&lt;/p&gt;
&lt;p&gt;当然，如果你的组织决定自己维护特定软件的版本，要么是因为开发者有最新最好版本的需求，需要派生软件源码并做出修改，要么是因为你喜欢给自己额外的工作量，这时你就会遇到问题。理想情况下，你应该已经配置好你的系统，让它在自动构建和打包定制版本软件时使用其它软件所用的同一套持续集成系统。然而，许多系统管理员仍旧在自己的本地主机上按照维基上的文档（但愿是最新的文档）使用过时的方法打包软件。不论使用哪种方法，你都需要明确你所使用的版本有没有安全缺陷，如果有，那必须确保新补丁安装到你定制版本的软件上了。&lt;/p&gt;
&lt;h3 id="_2"&gt;良好的补丁管理是怎样的&lt;/h3&gt;
&lt;p&gt;补丁管理首先要做的是检查软件的升级。首先，对于核心软件，你应该订阅相应 Linux 发行版的安全邮件列表，这样才能第一时间得知软件的安全升级情况。如果你使用的软件有些不是来自发行版的仓库，那么你也必须设法跟踪它们的安全更新。一旦接收到新的安全通知，你必须查阅通知细节，以此明确安全漏洞的严重程度，确定你的系统是否受影响，以及安全补丁的紧急性。&lt;/p&gt;
&lt;p&gt;一些组织仍在使用手动方式管理补丁。在这种方式下，当出现一个安全补丁，系统管理员就要凭借记忆，登录到各个服务器上进行检查。在确定了哪些服务器需要升级后，再使用服务器内建的包管理工具从发行版仓库升级这些软件。最后以相同的方式升级剩余的所有服务器。&lt;/p&gt;
&lt;p&gt;手动管理补丁的方式存在很多问题。首先，这么做会使补丁安装成为一个苦力活，安装补丁越多就需要越多人力成本，系统管理员就越可能推迟甚至完全忽略它。其次，手动管理方式依赖系统管理员凭借记忆去跟踪他或她所负责的服务器的升级情况。这非常容易导致有些服务器被遗漏而未能及时升级。&lt;/p&gt;
&lt;p&gt;补丁管理越快速简便，你就越可能把它做好。你应该构建一个系统，用来快速查询哪些服务器运行着特定的软件，以及这些软件的版本号，而且它最好还能够推送各种升级补丁。就个人而言，我倾向于使用 MCollective 这样的编排工具来完成这个任务，但是红帽提供的 Satellite 以及 Canonical 提供的 Landscape 也可以让你在统一的管理界面上查看服务器的软件版本信息，并且安装补丁。&lt;/p&gt;
&lt;p&gt;补丁安装还应该具有容错能力。你应该具备在不下线的情况下为服务安装补丁的能力。这同样适用于需要重启系统的内核补丁。我采用的方法是把我的服务器划分为不同的高可用组，lb1、app1、rabbitmq1 和 db1 在一个组，而lb2、app2、rabbitmq2 和 db2 在另一个组。这样，我就能一次升级一个组，而无须下线服务。&lt;/p&gt;
&lt;p&gt;所以，多快才能算快呢？对于少数没有附带服务的软件，你的系统最快应该能够在几分钟到一小时内安装好补丁（例如 bash 的 ShellShock 漏洞）。对于像 OpenSSL 这样需要重启服务的软件，以容错的方式安装补丁并重启服务的过程可能会花费稍多的时间，但这就是编排工具派上用场的时候。我在最近的关于 MCollective 的文章中（查看 2016 年 12 月和 2017 年 1 月的工单）给了几个使用 MCollective 实现补丁管理的例子。你最好能够部署一个系统，以具备容错性的自动化方式简化补丁安装和服务重启的过程。&lt;/p&gt;
&lt;p&gt;如果补丁要求重启系统，像内核补丁，那它会花费更多的时间。再次强调，自动化和编排工具能够让这个过程比你想象的还要快。我能够在一到两个小时内在生产环境中以容错方式升级并重启服务器，如果重启之间无须等待集群同步备份，这个过程还能更快。&lt;/p&gt;
&lt;p&gt;不幸的是，许多系统管理员仍坚信过时的观点，把持续运行时间（uptime）作为一种骄傲的象征——鉴于紧急内核补丁大约每年一次。对于我来说，这只能说明你没有认真对待系统的安全性！&lt;/p&gt;
&lt;p&gt;很多组织仍然使用无法暂时下线的单点故障的服务器，也因为这个原因，它无法升级或者重启。如果你想让系统更加安全，你需要去除过时的包袱，搭建一个至少能在深夜维护时段重启的系统。&lt;/p&gt;
&lt;p&gt;基本上，快速便捷的补丁管理也是一个成熟专业的系统管理团队所具备的标志。升级软件是所有系统管理员的必要工作之一，花费时间去让这个过程简洁快速，带来的好处远远不止是系统安全性。例如，它能帮助我们找到架构设计中的单点故障。另外，它还帮助鉴定出环境中过时的系统，给我们替换这些部分提供了动机。最后，当补丁管理做得足够好，它会节省系统管理员的时间，让他们把精力放在真正需要专业知识的地方。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Kyle Rankin 是高级安全与基础设施架构师，其著作包括： Linux Hardening in Hostile Networks，DevOps Troubleshooting 以及 The Official Ubuntu Server Book。同时，他还是 Linux Journal 的专栏作家。&lt;/p&gt;</content><category term="sysadmin"></category><category term="linux"></category><category term="翻译"></category></entry><entry><title>【译】使用 Docker 构建你的 Serverless 树莓派集群</title><link href="http://blog.xu0o0.me/posts/2017/10/your-serverless-raspberry-pi-cluster-with-docker.html" rel="alternate"></link><published>2017-10-28T00:00:00+08:00</published><updated>2017-10-28T00:00:00+08:00</updated><author><name>xu0o0</name></author><id>tag:blog.xu0o0.me,2017-10-28:/posts/2017/10/your-serverless-raspberry-pi-cluster-with-docker.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;原文链接：&lt;a href="https://blog.alexellis.io/your-serverless-raspberry-pi-cluster/"&gt;https://blog.alexellis.io/your-serverless-raspberry-pi-cluster/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原文作者：&lt;a href="https://twitter.com/alexellisuk"&gt;Alex Ellis&lt;/a&gt;
校对：&lt;a href="https://linux.cn/article-8811-1.html"&gt;Linux.CN&lt;/a&gt; 的 &lt;a href="https://github.com/wxy"&gt;wxy 前辈&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发布平台：&lt;a href="https://linux.cn/article-9007-1.html"&gt;Linux中国&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这篇博文将向你展示如何使用 Docker 和 &lt;a href="https://github.com/alexellis/faas"&gt;OpenFaaS&lt;/a&gt; 框架构建你自己的 Serverless 树莓派集群。大家常常问我能用他们的集群来做些什么？而这个应用完美匹配卡片尺寸的设备——只需添加更多的树莓派就能获取更强的计算能力。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Serverless” （无服务器）是事件驱动架构的一种设计模式，与“桥接模式”、“外观模式”、“工厂模式”和“云”这些名词一样，都是一种抽象概念。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="" src="https://blog.alexellis.io/content/images/2017/08/IMG_20170525_204840_crop.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片：3 个 Raspberry Pi Zero&lt;/em&gt; &lt;/p&gt;
&lt;p&gt;这是我在本文中描述的集群，用黄铜支架分隔每个设备。&lt;/p&gt;
&lt;h3 id="serverless"&gt;Serverless 是什么？它为何重要？&lt;/h3&gt;
&lt;p&gt;行业对于 …&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;原文链接：&lt;a href="https://blog.alexellis.io/your-serverless-raspberry-pi-cluster/"&gt;https://blog.alexellis.io/your-serverless-raspberry-pi-cluster/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原文作者：&lt;a href="https://twitter.com/alexellisuk"&gt;Alex Ellis&lt;/a&gt;
校对：&lt;a href="https://linux.cn/article-8811-1.html"&gt;Linux.CN&lt;/a&gt; 的 &lt;a href="https://github.com/wxy"&gt;wxy 前辈&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发布平台：&lt;a href="https://linux.cn/article-9007-1.html"&gt;Linux中国&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这篇博文将向你展示如何使用 Docker 和 &lt;a href="https://github.com/alexellis/faas"&gt;OpenFaaS&lt;/a&gt; 框架构建你自己的 Serverless 树莓派集群。大家常常问我能用他们的集群来做些什么？而这个应用完美匹配卡片尺寸的设备——只需添加更多的树莓派就能获取更强的计算能力。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Serverless” （无服务器）是事件驱动架构的一种设计模式，与“桥接模式”、“外观模式”、“工厂模式”和“云”这些名词一样，都是一种抽象概念。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="" src="https://blog.alexellis.io/content/images/2017/08/IMG_20170525_204840_crop.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片：3 个 Raspberry Pi Zero&lt;/em&gt; &lt;/p&gt;
&lt;p&gt;这是我在本文中描述的集群，用黄铜支架分隔每个设备。&lt;/p&gt;
&lt;h3 id="serverless"&gt;Serverless 是什么？它为何重要？&lt;/h3&gt;
&lt;p&gt;行业对于 “serverless” 这个术语的含义有几种解释。在这篇博文中，我们就把它理解为一种事件驱动的架构模式，它能让你用自己喜欢的任何语言编写轻量可复用的功能。&lt;a href="https://blog.alexellis.io/introducing-functions-as-a-service/"&gt;更多关于 Serverless 的资料&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://blog.alexellis.io/content/images/2017/08/evolution.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Serverless 架构也引出了“功能即服务服务”模式，简称 FaaS&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Serverless 的“功能”可以做任何事，但通常用于处理给定的输入——例如来自 GitHub、Twitter、PayPal、Slack、Jenkins CI pipeline 的事件；或者以树莓派为例，处理像红外运动传感器、激光绊网、温度计等真实世界的传感器的输入。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://www.raspberrypi.org/learning/parent-detector/images/pir_wiring.png" /&gt;&lt;/p&gt;
&lt;p&gt;Serverless 功能能够更好地结合第三方的后端服务，使系统整体的能力大于各部分之和。&lt;/p&gt;
&lt;p&gt;了解更多背景信息，可以阅读我最近一偏博文：&lt;a href="https://blog.alexellis.io/introducing-functions-as-a-service/"&gt;功能即服务（FaaS）简介&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id="_1"&gt;概述&lt;/h3&gt;
&lt;p&gt;我们将使用 &lt;a href="https://github.com/alexellis/faas"&gt;OpenFaaS&lt;/a&gt;，它能够让主机或者集群作为支撑 Serverless 功能运行的后端。任何能够使用 Docker 部署的可执行二进制文件、脚本或者编程语言都能在 &lt;a href="https://github.com/alexellis/faas"&gt;OpenFaaS&lt;/a&gt; 上运作，你可以根据速度和伸缩性选择部署的规模。另一个优点是，它还内建了用户界面和监控系统。&lt;/p&gt;
&lt;p&gt;这是我们要执行的步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在一个或多个主机上配置 Docker （树莓派 2 或者 3）；&lt;/li&gt;
&lt;li&gt;利用 Docker Swarm 将它们连接；&lt;/li&gt;
&lt;li&gt;部署 &lt;a href="https://github.com/alexellis/faas"&gt;OpenFaaS&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;使用 Python 编写我们的第一个功能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="docker-swarm"&gt;Docker Swarm&lt;/h3&gt;
&lt;p&gt;Docker 是一项打包和部署应用的技术，支持集群上运行，有着安全的默认设置，而且在搭建集群时只需要一条命令。OpenFaaS 使用 Docker 和 Swarm 在你的可用树莓派上传递你的 Serverless 功能。&lt;/p&gt;
&lt;p&gt;我推荐你在这个项目中使用带树莓派 2 或者 3，以太网交换机和&lt;a href="https://www.amazon.co.uk/Anker-PowerPort-Family-Sized-Technology-Smartphones/dp/B00PK1IIJY"&gt;强大的 USB 多端口电源适配器&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id="raspbian"&gt;准备 Raspbian&lt;/h3&gt;
&lt;p&gt;把 &lt;a href="http://downloads.raspberrypi.org/raspbian/images/raspbian-2017-07-05/"&gt;Raspbian Jessie Lite&lt;/a&gt; 写入 SD 卡（8GB 容量就正常工作了，但还是推荐使用 16GB 的 SD 卡）。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;注意：不要下载成 Raspbian Stretch 了&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;社区在努力让 Docker 支持 Raspbian Stretch，但是还未能做到完美运行。请从&lt;a href="http://downloads.raspberrypi.org/raspbian_lite/images/raspbian_lite-2017-07-05/"&gt;树莓派基金会网站&lt;/a&gt;下载 Jessie Lite 镜像。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我推荐使用 &lt;a href="https://etcher.io/"&gt;Etcher.io&lt;/a&gt; 烧写镜像。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在引导树莓派之前，你需要在引导分区创建名为 &lt;code&gt;ssh&lt;/code&gt; 的空白文件。这样才能允许远程登录。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="_2"&gt;接通电源，然后修改主机名&lt;/h4&gt;
&lt;p&gt;现在启动树莓派的电源并且使用 &lt;code&gt;ssh&lt;/code&gt; 连接：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ssh pi@raspberrypi.local
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;默认密码是 &lt;code&gt;raspberry&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用 &lt;code&gt;raspi-config&lt;/code&gt; 工具把主机名改为 &lt;code&gt;swarm-1&lt;/code&gt; 或者类似的名字，然后重启。&lt;/p&gt;
&lt;p&gt;当你到了这一步，你还可以把划分给 GPU （显卡）的内存设置为 16MB。&lt;/p&gt;
&lt;h4 id="docker"&gt;现在安装 Docker&lt;/h4&gt;
&lt;p&gt;我们可以使用通用脚本来安装：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ curl -sSL https://get.docker.com &lt;span class="p"&gt;|&lt;/span&gt; sh
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;这个安装方式在将来可能会发生变化。如上文所说，你的系统需要是 Jessie，这样才能得到一个确定的配置。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;你可能会看到类似下面的警告，不过你可以安全地忽略它并且成功安装上 Docker CE 17.05：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;WARNING&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;raspbian&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;no&lt;/span&gt; &lt;span class="n"&gt;longer&lt;/span&gt; &lt;span class="n"&gt;updated&lt;/span&gt; &lt;span class="err"&gt;@&lt;/span&gt; &lt;span class="n"&gt;https&lt;/span&gt;&lt;span class="o"&gt;://&lt;/span&gt;&lt;span class="kd"&gt;get&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;docker&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;  
&lt;span class="n"&gt;Installing&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;legacy&lt;/span&gt; &lt;span class="n"&gt;docker&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;engine&lt;/span&gt; &lt;span class="kd"&gt;package&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;之后，用下面这个命令确保你的用户帐号可以访问 Docker 客户端：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ usermod pi -aG docker
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;如果你的用户名不是 &lt;code&gt;pi&lt;/code&gt;，那就把它替换成你的用户名。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id="_3"&gt;修改默认密码&lt;/h4&gt;
&lt;p&gt;输入 &lt;code&gt;$sudo passwd pi&lt;/code&gt;，然后设置一个新密码，请不要跳过这一步！&lt;/p&gt;
&lt;h4 id="_4"&gt;重复以上步骤&lt;/h4&gt;
&lt;p&gt;现在为其它的树莓派重复上述步骤。&lt;/p&gt;
&lt;h3 id="swarm"&gt;创建你的 Swarm 集群&lt;/h3&gt;
&lt;p&gt;登录你的第一个树莓派，然后输入下面的命令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker swarm init
Swarm initialized: current node &lt;span class="o"&gt;(&lt;/span&gt;3ra7i5ldijsffjnmubmsfh767&lt;span class="o"&gt;)&lt;/span&gt; is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join &lt;span class="se"&gt;\&lt;/span&gt;
    --token SWMTKN-1-496mv9itb7584pzcddzj4zvzzfltgud8k75rvujopw15n3ehzu-af445b08359golnzhncbdj9o3 &lt;span class="se"&gt;\&lt;/span&gt;
    &lt;span class="m"&gt;192&lt;/span&gt;.168.0.79:2377
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;你会看到它显示了一个口令，以及其它节点加入集群的命令。接下来使用 &lt;code&gt;ssh&lt;/code&gt; 登录每个树莓派，运行这个加入集群的命令。&lt;/p&gt;
&lt;p&gt;等待连接完成后，在第一个树莓派上查看集群的节点：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS  
3ra7i5ldijsffjnmubmsfh767 *   swarm1              Ready               Active              Leader  
k9mom28s2kqxocfq1fo6ywu63     swarm3              Ready               Active  
y2p089bs174vmrlx30gc77h4o     swarm4              Ready               Active  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;恭喜你！你现在拥有一个树莓派集群了！&lt;/p&gt;
&lt;h4 id="_5"&gt;更多关于集群的内容&lt;/h4&gt;
&lt;p&gt;你可以看到三个节点启动运行。这时只有一个节点是集群管理者。如果我们的管理节点_死机_了，集群就进入了不可修复的状态。我们可以通过添加冗余的管理节点解决这个问题。而且它们依然会运行工作负载，除非你明确设置了让你的服务只运作在工作节点上。&lt;/p&gt;
&lt;p&gt;要把一个工作节点升级为管理节点，只需要在其中一个管理节点上运行 &lt;code&gt;docker node promote &amp;lt;node_name&amp;gt;&lt;/code&gt; 命令。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意： Swarm 命令，例如 &lt;code&gt;docker service ls&lt;/code&gt; 或者 &lt;code&gt;docker node ls&lt;/code&gt; 只能在管理节点上运行。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;想深入了解管理节点与工作节点如何保持一致性，可以查阅 &lt;a href="https://docs.docker.com/engine/swarm/admin_guide/"&gt;Docker Swarm 管理指南&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id="openfaas"&gt;OpenFaaS&lt;/h3&gt;
&lt;p&gt;现在我们继续部署程序，让我们的集群能够运行 Serverless 功能。&lt;a href="https://github.com/alexellis/faas"&gt;OpenFaaS&lt;/a&gt; 是一个利用 Docker 在任何硬件或者云上让任何进程或者容器成为一个 Serverless 功能的框架。因为 Docker 和 Golang 的可移植性，它也能很好地运行在树莓派上。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://blog.alexellis.io/content/images/2017/08/faas_side.png" /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果你支持 &lt;a href="https://github.com/alexellis/faas"&gt;OpenFaaS&lt;/a&gt;，希望你能 &lt;strong&gt;星标&lt;/strong&gt; &lt;a href="https://github.com/alexellis/faas"&gt;OpenFaaS&lt;/a&gt; 的 GitHub 仓库。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;登录你的第一个树莓派（你运行 &lt;code&gt;docker swarm init&lt;/code&gt; 的节点），然后部署这个项目：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git clone https://github.com/alexellis/faas/
$ &lt;span class="nb"&gt;cd&lt;/span&gt; faas
$ ./deploy_stack.armhf.sh
Creating network func_functions  
Creating service func_gateway  
Creating service func_prometheus  
Creating service func_alertmanager  
Creating service func_nodeinfo  
Creating service func_markdown  
Creating service func_wordcount  
Creating service func_echoit  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;你的其它树莓派会收到 Docer Swarm 的指令，开始从网上拉取这个 Docker 镜像，并且解压到 SD 卡上。这些工作会分布到各个节点上，所以没有哪个节点产生过高的负载。&lt;/p&gt;
&lt;p&gt;这个过程会持续几分钟，你可以用下面指令查看它的完成状况：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ watch &lt;span class="s1"&gt;&amp;#39;docker service ls&amp;#39;&lt;/span&gt;
ID                  NAME                MODE                REPLICAS            IMAGE                                   PORTS  
57ine9c10xhp        func_wordcount      replicated          &lt;span class="m"&gt;1&lt;/span&gt;/1                 functions/alpine:latest-armhf  
d979zipx1gld        func_prometheus     replicated          &lt;span class="m"&gt;1&lt;/span&gt;/1                 alexellis2/prometheus-armhf:1.5.2       *:9090-&amp;gt;9090/tcp  
f9yvm0dddn47        func_echoit         replicated          &lt;span class="m"&gt;1&lt;/span&gt;/1                 functions/alpine:latest-armhf  
lhbk1fc2lobq        func_markdown       replicated          &lt;span class="m"&gt;1&lt;/span&gt;/1                 functions/markdownrender:latest-armhf  
pj814yluzyyo        func_alertmanager   replicated          &lt;span class="m"&gt;1&lt;/span&gt;/1                 alexellis2/alertmanager-armhf:0.5.1     *:9093-&amp;gt;9093/tcp  
q4bet4xs10pk        func_gateway        replicated          &lt;span class="m"&gt;1&lt;/span&gt;/1                 functions/gateway-armhf:0.6.0           *:8080-&amp;gt;8080/tcp  
v9vsvx73pszz        func_nodeinfo       replicated          &lt;span class="m"&gt;1&lt;/span&gt;/1                 functions/nodeinfo:latest-armhf  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;我们希望看到每个服务都显示 “1/1”。&lt;/p&gt;
&lt;p&gt;你可以根据服务名查看该服务被调度到哪个树莓派上：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker service ps func_markdown
ID                  IMAGE                                   NODE    STATE  
func_markdown.1     functions/markdownrender:latest-armhf   swarm4  Running  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;状态一项应该显示 &lt;code&gt;Running&lt;/code&gt;，如果它是 &lt;code&gt;Pending&lt;/code&gt;，那么镜像可能还在下载中。&lt;/p&gt;
&lt;p&gt;在这时，查看树莓派的 IP 地址，然后在浏览器中访问它的 8080 端口：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ ifconfig
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;例如，如果你的 IP 地址是 192.168.0.100，那就访问 http://192.168.0.100:8080 。&lt;/p&gt;
&lt;p&gt;这是你会看到 FaaS UI（也叫 API 网关）。这是你定义、测试、调用功能的地方。&lt;/p&gt;
&lt;p&gt;点击名称为 “func_markdown” 的 Markdown 转换功能，输入一些 Markdown（这是 Wikipedia 用来组织内容的语言）文本。&lt;/p&gt;
&lt;p&gt;然后点击 “invoke”。你会看到调用计数增加，屏幕下方显示功能调用的结果。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://blog.alexellis.io/content/images/2017/08/faas_rpi.png" /&gt;&lt;/p&gt;
&lt;h3 id="serverless_1"&gt;部署你的第一个 Serverless 功能：&lt;/h3&gt;
&lt;p&gt;这一节的内容已经有相关的教程，但是我们需要几个步骤来配置树莓派。&lt;/p&gt;
&lt;h4 id="faas-cli"&gt;获取 FaaS-CLI&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ curl -sSL cli.openfaas.com &lt;span class="p"&gt;|&lt;/span&gt; sudo sh
armv7l  
Getting package https://github.com/alexellis/faas-cli/releases/download/0.4.5-b/faas-cli-armhf  
&lt;/pre&gt;&lt;/div&gt;


&lt;h4 id="_6"&gt;下载样例&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git clone https://github.com/alexellis/faas-cli
$ &lt;span class="nb"&gt;cd&lt;/span&gt; faas-cli
&lt;/pre&gt;&lt;/div&gt;


&lt;h4 id="_7"&gt;为树莓派修补样例模版&lt;/h4&gt;
&lt;p&gt;我们临时修改我们的模版，让它们能在树莓派上工作：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ cp template/node-armhf/Dockerfile template/node/
$ cp template/python-armhf/Dockerfile template/python/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这么做是因为树莓派和我们平时关注的大多数计算机使用不一样的处理器架构。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;了解 Docker 在树莓派上的最新状况，请查阅： &lt;a href="https://blog.alexellis.io/5-things-docker-rpi/"&gt;你需要了解的五件事&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;现在你可以跟着下面为 PC、笔记本和云端所写的教程操作，但我们在树莓派上要先运行一些命令。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.alexellis.io/first-faas-python-function"&gt;使用 OpenFaaS 运行你的第一个 Serverless Python 功能&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意第 3 步：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把你的功能放到先前从 GitHub 下载的 &lt;code&gt;faas-cli&lt;/code&gt; 文件夹中，而不是 &lt;code&gt;~/functinos/hello-python&lt;/code&gt; 里。&lt;/li&gt;
&lt;li&gt;同时，在 &lt;code&gt;stack.yml&lt;/code&gt; 文件中把 &lt;code&gt;localhost&lt;/code&gt; 替换成第一个树莓派的 IP 地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;集群可能会花费几分钟把 Serverless 功能下载到相关的树莓派上。你可以用下面的命令查看你的服务，确保副本一项显示 “1/1”：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ watch &lt;span class="s1"&gt;&amp;#39;docker service ls&amp;#39;&lt;/span&gt;
pv27thj5lftz        hello-python        replicated          &lt;span class="m"&gt;1&lt;/span&gt;/1                 alexellis2/faas-hello-python-armhf:latest  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;继续阅读教程：&lt;/strong&gt; &lt;a href="https://blog.alexellis.io/first-faas-python-function"&gt;使用 OpenFaaS 运行你的第一个 Serverless Python 功能&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;关于 Node.js 或者其它语言的更多信息，可以进一步访问 &lt;a href="https://github.com/alexellis/faas"&gt;FaaS 仓库&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id="_8"&gt;检查功能的指标&lt;/h3&gt;
&lt;p&gt;既然使用 Serverless，你也不想花时间监控你的功能。幸运的是，OpenFaaS 内建了 &lt;a href="https://prometheus.io/"&gt;Prometheus&lt;/a&gt; 指标检测，这意味着你可以追踪每个功能的运行时长和调用频率。&lt;/p&gt;
&lt;h4 id="_9"&gt;指标驱动自动伸缩&lt;/h4&gt;
&lt;p&gt;如果你给一个功能生成足够的负载，OpenFaaS 将自动扩展你的功能；当需求消失时，你又会回到单一副本的状态。&lt;/p&gt;
&lt;p&gt;这个请求样例你可以复制到浏览器中：&lt;/p&gt;
&lt;p&gt;只要把 IP 地址改成你的即可。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://blog.alexellis.io/content/images/2017/08/call_rate.png" /&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;http://192.168.0.25:9090/graph?g0.range_input=15m&amp;amp;g0.stacked=1&amp;amp;g0.expr=rate(gateway_function_invocation_total%5B20s%5D)&amp;amp;g0.tab=0&amp;amp;g1.range_input=1h&amp;amp;g1.expr=gateway_service_count&amp;amp;g1.tab=0  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这些请求使用 PromQL（Prometheus 请求语言）编写。第一个请求返回功能调用的频率：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;rate(gateway_function_invocation_total[20s])  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;第二个请求显示每个功能的副本数量，最开始应该是每个功能只有一个副本。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;gateway_service_count  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如果你想触发自动扩展，你可以在树莓派上尝试下面指令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt; curl -4 localhost:8080/function/func_echoit --data &lt;span class="s2"&gt;&amp;quot;hello world&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;查看 Prometheus 的 “alerts” 页面，可以知道你是否产生足够的负载来触发自动扩展。如果没有，你可以尝试在多个终端同时运行上面的指令。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://blog.alexellis.io/content/images/2017/08/alerts.png" /&gt;&lt;/p&gt;
&lt;p&gt;当你降低负载，副本数量显示在你的第二个图表中，并且 &lt;code&gt;gateway_service_count&lt;/code&gt; 指标再次降回 1。&lt;/p&gt;
&lt;h3 id="_10"&gt;结束演讲&lt;/h3&gt;
&lt;p&gt;我们现在配置好了 Docker、Swarm， 并且让 OpenFaaS 运行代码，把树莓派像大型计算机一样使用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;希望大家支持这个项目，&lt;strong&gt;星标&lt;/strong&gt; &lt;a href="https://github.com/alexellis/faas"&gt;FaaS 的 GitHub 仓库&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;你是如何搭建好了自己的 Docker Swarm 集群并且运行 OpenFaaS 的呢？在 Twitter &lt;a href="https://twitter.com/alexellisuk"&gt;@alexellisuk&lt;/a&gt; 上分享你的照片或推文吧。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;观看我在 Dockercon 上关于 OpenFaaS 的视频&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我在 &lt;a href="https://blog.alexellis.io/dockercon-2017-captains-log/"&gt;Austin 的 Dockercon&lt;/a&gt; 上展示了 OpenFaaS。——观看介绍和互动例子的视频： https://www.youtube.com/embed/-h2VTE9WnZs &lt;/p&gt;
&lt;p&gt;有问题？在下面的评论中提出，或者给我发邮件，邀请我进入你和志同道合者讨论树莓派、Docker、Serverless 的 Slack channel。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;想要学习更多关于树莓派上运行 Docker 的内容？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我建议从 &lt;a href="https://blog.alexellis.io/5-things-docker-rpi/"&gt;你需要了解的五件事&lt;/a&gt; 开始，它包含了安全性、树莓派和普通 PC 间微妙差别等话题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.alexellis.io/dockercon-tips-docker-raspberry-pi/"&gt;Dockercon tips: Docker &amp;amp; Raspberry Pi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.alexellis.io/gpio-on-swarm/"&gt;Control GPIO with Docker Swarm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.alexellis.io/docker-engine-in-your-pocket/"&gt;Is that a Docker Engine in your pocket??&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;</content><category term="container"></category><category term="docker"></category><category term="linux"></category><category term="serverless"></category><category term="翻译"></category></entry><entry><title>【译】Kubernetes 是什么？</title><link href="http://blog.xu0o0.me/posts/2017/09/what-is-kubernetes.html" rel="alternate"></link><published>2017-09-11T00:00:00+08:00</published><updated>2017-09-11T00:00:00+08:00</updated><author><name>xu0o0</name></author><id>tag:blog.xu0o0.me,2017-09-11:/posts/2017/09/what-is-kubernetes.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;原文链接：&lt;a href="https://www.redhat.com/en/containers/what-is-kubernetes"&gt;https://www.redhat.com/en/containers/what-is-kubernetes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原文作者：&lt;a href="https://www.redhat.com/"&gt;www.redhat.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;校对：&lt;a href="https://linux.cn/article-8858-1.html"&gt;Linux.CN&lt;/a&gt; 的 &lt;a href="https://github.com/wxy"&gt;wxy 前辈&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发布平台：&lt;a href="https://linux.cn/article-8858-1.html"&gt;Linux中国&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="" src="https://www.redhat.com/cms/managed-files/styles/max_size/s3/subtopic-header-template-crane-2000x560.png?itok=xht5Sni6" /&gt;&lt;/p&gt;
&lt;p&gt;Kubernetes，简称 k8s（k，8 个字符，s——明白了？）或者 “kube”，是一个开源的 &lt;a href="https://www.redhat.com/en/containers/whats-a-linux-container"&gt;Linux 容器&lt;/a&gt;自动化运维平台，它消除了容器化应用程序在部署、伸缩时涉及到的许多手动操作。换句话说，你可以将多台主机组合成集群来运行 Linux 容器，而 Kubernetes 可以帮助你简单高效地管理那些集群。构成这些集群的主机还可以跨越&lt;a href="https://www.redhat.com/en/topics/cloud-computing/what-is-public-cloud"&gt;公有云&lt;/a&gt;、&lt;a href="https://www.redhat.com/en/topics/cloud-computing/what-is-private-cloud"&gt;私有云&lt;/a&gt;以及混合云。&lt;/p&gt;
&lt;p&gt;Kubernetes 最开始是由 Google …&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;原文链接：&lt;a href="https://www.redhat.com/en/containers/what-is-kubernetes"&gt;https://www.redhat.com/en/containers/what-is-kubernetes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原文作者：&lt;a href="https://www.redhat.com/"&gt;www.redhat.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;校对：&lt;a href="https://linux.cn/article-8858-1.html"&gt;Linux.CN&lt;/a&gt; 的 &lt;a href="https://github.com/wxy"&gt;wxy 前辈&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发布平台：&lt;a href="https://linux.cn/article-8858-1.html"&gt;Linux中国&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="" src="https://www.redhat.com/cms/managed-files/styles/max_size/s3/subtopic-header-template-crane-2000x560.png?itok=xht5Sni6" /&gt;&lt;/p&gt;
&lt;p&gt;Kubernetes，简称 k8s（k，8 个字符，s——明白了？）或者 “kube”，是一个开源的 &lt;a href="https://www.redhat.com/en/containers/whats-a-linux-container"&gt;Linux 容器&lt;/a&gt;自动化运维平台，它消除了容器化应用程序在部署、伸缩时涉及到的许多手动操作。换句话说，你可以将多台主机组合成集群来运行 Linux 容器，而 Kubernetes 可以帮助你简单高效地管理那些集群。构成这些集群的主机还可以跨越&lt;a href="https://www.redhat.com/en/topics/cloud-computing/what-is-public-cloud"&gt;公有云&lt;/a&gt;、&lt;a href="https://www.redhat.com/en/topics/cloud-computing/what-is-private-cloud"&gt;私有云&lt;/a&gt;以及混合云。&lt;/p&gt;
&lt;p&gt;Kubernetes 最开始是由 Google 的工程师设计开发的。Google 作为 &lt;a href="https://en.wikipedia.org/wiki/Cgroups"&gt;Linux 容器技术的早期贡献者&lt;/a&gt;之一，曾公开演讲介绍 &lt;a href="https://speakerdeck.com/jbeda/containers-at-scale"&gt;Google 如何将一切都运行于容器之中&lt;/a&gt;（这是 Google 的云服务背后的技术）。Google 一周内的容器部署超过 20 亿次，全部的工作都由内部平台 &lt;a href="http://blog.kubernetes.io/2015/04/borg-predecessor-to-kubernetes.html"&gt;Borg&lt;/a&gt; 支撑。Borg 是 Kubernetes 的前身，几年来开发 Borg 的经验教训也成了影响 Kubernetes 中许多技术的主要因素。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;趣闻: Kubernetes logo 中的七个辐条来源于项目原先的名称, “&lt;a href="https://cloudplatform.googleblog.com/2016/07/from-Google-to-the-world-the-Kubernetes-origin-story.html"&gt;Seven of Nine 项目&lt;/a&gt;”（LCTT 译注：Borg 是「星际迷航」中的一个宇宙种族，Seven of Nine 是该种族的一名女性角色）。&lt;/em&gt; &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://kubernetes.io/images/favicon.png" /&gt;&lt;/p&gt;
&lt;p&gt;红帽作为最早与 Google 合作开发 Kubernetes 的公司之一（甚至早于 Kubernetes 的发行），已经是 Kubernetes 上游项目的&lt;a href="http://stackalytics.com/?project_type=kubernetes-group&amp;amp;metric=commits"&gt;第二大贡献者&lt;/a&gt;。Google 在 2015 年把 Kubernetes 项目捐献给了新成立的 &lt;ruby&gt;&lt;a href="https://www.cncf.io/"&gt;云计算基金会&lt;/a&gt;&lt;rt&gt;Cloud Native Computing Foundation&lt;/rt&gt;&lt;/ruby&gt;（CNCF）。&lt;/p&gt;
&lt;h3 id="kubernetes"&gt;为什么你需要 Kubernetes ？&lt;/h3&gt;
&lt;p&gt;真实的生产环境应用会包含多个容器，而这些容器还很可能会跨越多个服务器主机部署。Kubernetes 提供了为那些工作负载大规模部署容器的编排与管理能力。Kubernetes 编排让你能够构建多容器的应用服务，在集群上调度或伸缩这些容器，以及管理它们随时间变化的健康状态。&lt;/p&gt;
&lt;p&gt;Kubernetes 也需要与网络、存储、安全、监控等其它服务集成才能提供综合性的容器基础设施。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Kubernetes 解释－图表" src="https://www.redhat.com/cms/managed-files/styles/max_size/s3/kubernetes-diagram-902x416.png?itok=C_wxL4HV" title="Kubernetes 解释－图表" /&gt; &lt;/p&gt;
&lt;p&gt;当然，这取决于你如何在你的环境中使用容器。一个初步的 Linux 容器应用程序把容器视作高效、快速的虚拟机。一旦把它部署到生产环境或者扩展为多个应用，很显然你需要许多组托管在相同位置的容器合作提供某个单一的服务。随着这些容器的累积，你的运行环境中容器的数量会急剧增加，复杂度也随之增长。&lt;/p&gt;
&lt;p&gt;Kubernetes 通过将容器分类组成 “pod” 来解决了容器增殖带来的许多常见问题。pod 为容器分组提供了一层抽象，以此协助你调度工作负载以及为这些容器提供类似网络与存储这类必要的服务。Kubernetes 的其它组件帮助你对 pod 进行负载均衡，以保证有合适数量的容器支撑你的工作负载。&lt;/p&gt;
&lt;p&gt;正确实施的 Kubernetes，结合类似 &lt;a href="http://www.projectatomic.io/registry/"&gt;Atomic Registry&lt;/a&gt;、&lt;a href="http://openvswitch.org/"&gt;Open vSwitch&lt;/a&gt;、&lt;a href="https://github.com/kubernetes/heapster"&gt;heapster&lt;/a&gt;、&lt;a href="https://oauth.net/"&gt;OAuth&lt;/a&gt; 和 &lt;a href="https://selinuxproject.org/page/Main_Page"&gt;SELinux&lt;/a&gt; 的开源项目，让你可以管理你自己的整个容器基础设施。&lt;/p&gt;
&lt;h3 id="kubernetes_1"&gt;Kubernetes 能做些什么？&lt;/h3&gt;
&lt;p&gt;在生产环境中使用 Kubernetes 的主要优势在于它提供了在物理机或虚拟机集群上调度和运行容器的平台。更宽泛地说，它能帮你在生产环境中实现可以依赖的基于容器的基础设施。而且，由于 Kubernetes 本质上就是运维任务的自动化平台，你可以执行一些其它应用程序平台或管理系统支持的操作，只不过操作对象变成了容器。&lt;/p&gt;
&lt;p&gt;有了 Kubernetes，你可以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;跨主机编排容器。&lt;/li&gt;
&lt;li&gt;更充分地利用硬件资源来最大化地满足企业应用的需求。&lt;/li&gt;
&lt;li&gt;控制与自动化应用的部署与升级。&lt;/li&gt;
&lt;li&gt;为有状态的应用程序挂载和添加存储器。&lt;/li&gt;
&lt;li&gt;线上扩展或裁剪容器化应用程序与它们的资源。&lt;/li&gt;
&lt;li&gt;声明式的容器管理，保证所部署的应用按照我们部署的方式运作。&lt;/li&gt;
&lt;li&gt;通过自动布局、自动重启、自动复制、自动伸缩实现应用的状态检查与自我修复。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然而 Kubernetes 依赖其它项目来提供完整的编排服务。结合其它开源项目作为其组件，你才能充分感受到 Kubernetes 的能力。这些必要组件包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;仓库：Atomic Registry、Docker Registry 等。&lt;/li&gt;
&lt;li&gt;网络：OpenvSwitch 和智能边缘路由等。&lt;/li&gt;
&lt;li&gt;监控：heapster、kibana、hawkular 和 elastic。&lt;/li&gt;
&lt;li&gt;安全：LDAP、SELinux、 RBAC 与 支持多租户的 OAUTH。&lt;/li&gt;
&lt;li&gt;自动化：通过 Ansible 的 playbook 进行集群的安装和生命周期管理。&lt;/li&gt;
&lt;li&gt;服务：大量事先创建好的常用应用模板。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift"&gt;红帽 OpenShift 为容器部署预先集成了上面这些组件。&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="kubernetes_2"&gt;Kubernetes 入门&lt;/h3&gt;
&lt;p&gt;和其它技术一样，大量的专有名词有可能成为入门的障碍。下面解释一些通用的术语，希望帮助你理解 Kubernetes。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Master（主节点）：&lt;/strong&gt; 控制 Kubernetes 节点的机器，也是创建作业任务的地方。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Node（节点）：&lt;/strong&gt; 这些机器在 Kubernetes 主节点的控制下执行被分配的任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pod：&lt;/strong&gt; 由一个或多个容器构成的集合，作为一个整体被部署到一个单一节点。同一个 pod 中的容器共享 IP 地址、进程间通讯（IPC）、主机名以及其它资源。Pod 将底层容器的网络和存储抽象出来，使得集群内的容器迁移更为便捷。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Replication controller（复制控制器）：&lt;/strong&gt; 控制一个 pod 在集群上运行的实例数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Service（服务）：&lt;/strong&gt; 将服务内容与具体的 pod 分离。Kubernetes 服务代理负责自动将服务请求分发到正确的 pod 处，不管 pod 移动到集群中的什么位置，甚至可以被替换掉。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kubelet：&lt;/strong&gt; 这个守护进程运行在各个工作节点上，负责获取容器列表，保证被声明的容器已经启动并且正常运行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;kubectl：&lt;/strong&gt; 这是 Kubernetes 的命令行配置工具。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://kubernetes.io/docs/reference/"&gt;上面这些知识就足够了吗？不，这仅仅是一小部分，更多内容请查看 Kubernetes 术语表。&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="kubernetes_3"&gt;生产环境中使用 Kubernetes&lt;/h3&gt;
&lt;p&gt;Kubernetes 是开源的，所以没有正式的技术支持机构为你的商业业务提供支持。如果在生产环境使用 Kubernetes 时遇到问题，你恐怕不会太愉快，当然你的客户也不会太高兴。&lt;/p&gt;
&lt;p&gt;这就是&lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift"&gt;红帽 OpenShift&lt;/a&gt; 要解决的问题。OpenShift 是为企业提供的 Kubernetes ——并且集成了更多的组件。OpenShift 包含了强化 Kubernetes 功能、使其更适用于企业场景的额外部件，包括仓库、网络、监控、安全、自动化和服务在内。OpenShift 使得开发者能够在具有伸缩性、控制和编排能力的云端开发、托管和部署容器化的应用，快速便捷地把想法转变为业务。&lt;/p&gt;
&lt;p&gt;而且，OpenShift 还是由头号开源领导公司红帽支持和开发的。&lt;/p&gt;
&lt;h3 id="kubernetes_4"&gt;Kubernetes 如何适用于你的基础设施&lt;/h3&gt;
&lt;p&gt;&lt;img alt="Kubernetes 图表" src="https://www.redhat.com/cms/managed-files/styles/max_size/s3/kubernetes-diagram-2-824x437.png?itok=KmhLmkgi" title="Kubernetes 图表" /&gt; &lt;/p&gt;
&lt;p&gt;Kubernetes 运行在操作系统（例如 &lt;a href="https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux/options"&gt;Red Hat Enterprise Linux Atomic Host&lt;/a&gt;）之上，操作着该节点上运行的容器。Kubernetes 主节点（master）从管理员（或者 DevOps 团队）处接受命令，再把指令转交给附属的节点。这种带有大量服务的切换工作自动决定最适合该任务的节点，然后在该节点上分配资源并指派 pod 来完成任务请求。&lt;/p&gt;
&lt;p&gt;所以从基础设施的角度，管理容器的方式发生了一点小小的变化。对容器的控制在更高的层次进行，提供了更佳的控制方式，而无需用户微观管理每个单独的容器或者节点。必要的工作则主要集中在如何指派 Kubernetes 主节点、定义节点和 pod 等问题上。&lt;/p&gt;
&lt;h4 id="docker-kubernetes"&gt;docker 在 Kubernetes 中的角色&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://www.redhat.com/en/containers/what-is-docker"&gt;Docker&lt;/a&gt; 技术依然执行它原本的任务。当 kubernetes 把 pod 调度到节点上，节点上的 kubelet 会指示 docker 启动特定的容器。接着，kubelet 会通过 docker 持续地收集容器的信息，然后提交到主节点上。Docker 如往常一样拉取容器镜像、启动或停止容器。不同点仅仅在于这是由自动化系统控制而非管理员在每个节点上手动操作的。&lt;/p&gt;
&lt;hr /&gt;</content><category term="container"></category><category term="docker"></category><category term="linux"></category><category term="kubernetes"></category><category term="翻译"></category></entry><entry><title>【译】Linux 容器演化史</title><link href="http://blog.xu0o0.me/posts/2017/08/how-linux-containers-evolved.html" rel="alternate"></link><published>2017-08-29T00:00:00+08:00</published><updated>2017-08-29T00:00:00+08:00</updated><author><name>xu0o0</name></author><id>tag:blog.xu0o0.me,2017-08-29:/posts/2017/08/how-linux-containers-evolved.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;原文链接：&lt;a href="https://opensource.com/article/17/7/how-linux-containers-evolved"&gt;https://opensource.com/article/17/7/how-linux-containers-evolved&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原文作者：&lt;a href="https://opensource.com/users/rhatdan"&gt;Daniel J Walsh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;校对：&lt;a href="https://linux.cn/article-8811-1.html"&gt;Linux.CN&lt;/a&gt; 的 &lt;a href="https://github.com/wxy"&gt;wxy 前辈&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发布平台：&lt;a href="https://linux.cn/article-8811-1.html"&gt;Linux中国&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="How Linux containers have evolved" src="https://opensource.com/sites/default/files/styles/image-full-size/public/lead-images/containers_2015-3-osdc-lead.png?itok=O6aivM_W" title="Linux 容器的演化过程" /&gt;&lt;/p&gt;
&lt;h3 id="linux"&gt;Linux 容器是如何演变的&lt;/h3&gt;
&lt;p&gt;在过去几年内，容器不仅成为了开发者们热议的话题，还受到了企业的关注。持续增长的关注使得在它的安全性、可扩展性以及互用性等方面的需求也得以增长。满足这些需求需要很大的工程量，下面我们讲讲在红帽这样的企业级这些工程是如何发展的。&lt;/p&gt;
&lt;p&gt;我在 2013 年秋季第一次遇到 Docker 公司（Docker.io）的代表，那时我们在设法使 Red Hat Enterprise Linux (RHEL) 支持 Docker 容器（现在 Docker 项目的一部分已经更名为 &lt;em&gt;Moby …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;原文链接：&lt;a href="https://opensource.com/article/17/7/how-linux-containers-evolved"&gt;https://opensource.com/article/17/7/how-linux-containers-evolved&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原文作者：&lt;a href="https://opensource.com/users/rhatdan"&gt;Daniel J Walsh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;校对：&lt;a href="https://linux.cn/article-8811-1.html"&gt;Linux.CN&lt;/a&gt; 的 &lt;a href="https://github.com/wxy"&gt;wxy 前辈&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;发布平台：&lt;a href="https://linux.cn/article-8811-1.html"&gt;Linux中国&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="How Linux containers have evolved" src="https://opensource.com/sites/default/files/styles/image-full-size/public/lead-images/containers_2015-3-osdc-lead.png?itok=O6aivM_W" title="Linux 容器的演化过程" /&gt;&lt;/p&gt;
&lt;h3 id="linux"&gt;Linux 容器是如何演变的&lt;/h3&gt;
&lt;p&gt;在过去几年内，容器不仅成为了开发者们热议的话题，还受到了企业的关注。持续增长的关注使得在它的安全性、可扩展性以及互用性等方面的需求也得以增长。满足这些需求需要很大的工程量，下面我们讲讲在红帽这样的企业级这些工程是如何发展的。&lt;/p&gt;
&lt;p&gt;我在 2013 年秋季第一次遇到 Docker 公司（Docker.io）的代表，那时我们在设法使 Red Hat Enterprise Linux (RHEL) 支持 Docker 容器（现在 Docker 项目的一部分已经更名为 &lt;em&gt;Moby&lt;/em&gt;）的运行。在移植过程中，我们遇到了一些问题。处理容器镜像分层所需的写时拷贝（COW）文件系统成了我们第一个重大阻碍。Red Hat 最终贡献了一些 COW 文件系统实现，包括 &lt;a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Logical_Volume_Manager_Administration/device_mapper.html"&gt;Device Mapper&lt;/a&gt;、&lt;a href="https://btrfs.wiki.kernel.org/index.php/Main_Page"&gt;btrfs&lt;/a&gt;，以及 &lt;a href="https://www.kernel.org/doc/Documentation/filesystems/overlayfs.txt"&gt;OverlayFS&lt;/a&gt; 的第一个版本。在 RHEL 上，我们默认使用 Device Mapper， 但是我们在 OverlayFS 上也已经取得了很大进展。&lt;/p&gt;
&lt;p&gt;我们在用于启动容器的工具上遇到了第二个主要障碍。那时的上游 docker 使用 &lt;a href="https://linuxcontainers.org/"&gt;LXC&lt;/a&gt; 工具来启动容器，然而我们不想在 RHEL 上支持 LXC 工具集。而且在与上游 docker 合作之前，我们已经与 &lt;a href="https://libvirt.org/"&gt;libvrit&lt;/a&gt; 团队携手构建了 &lt;a href="http://sandbox.libvirt.org/"&gt;virt-sandbox&lt;/a&gt; 工具，它使用 &lt;code&gt;libvrit-lxc&lt;/code&gt; 来启动容器。&lt;/p&gt;
&lt;p&gt;在那时，红帽里有员工提到一个好办法，换掉 LXC 工具集而添加桥接器，以便 docker 守护进程通过 &lt;code&gt;libvirt-lxc&lt;/code&gt; 与 libvirt 通讯来启动容器。这个方案也有一些顾虑。考虑下面这个例子，使用 Docker 客户端（&lt;code&gt;docker-cli&lt;/code&gt;）来启动容器，各层调用会在容器进程（&lt;code&gt;pid1OfContainer&lt;/code&gt;）之前依次启动：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;docker-cli → docker-daemon → libvirt-lxc → pid1OfContainer&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我不是很喜欢这个方案，因为它在启动容器的工具与最终的容器进程之间有两个守护进程。&lt;/p&gt;
&lt;p&gt;我的团队与上游 docker 开发者合作实现了一个原生的 &lt;a href="https://opensource.com/article/17/6/getting-started-go"&gt;Go 编程语言&lt;/a&gt; 版本的容器运行时，叫作 &lt;a href="https://github.com/opencontainers/runc/tree/master/libcontainer"&gt;libcontainer&lt;/a&gt;。这个库作为 [OCI 运行时规范]的最初版实现与 runc 一同发布。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;docker-cli → docker-daemon @ pid1OfContainer&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大多数人误认为当他们执行一个容器时，容器进程是作为 &lt;code&gt;docker-cli&lt;/code&gt; 的子进程运行的。实际上他们执行的是一个客户端/服务端请求操作，容器进程是在一个完全单独的环境作为子进程运行的。这个客户端/服务端请求会导致不稳定性和潜在的安全问题，而且会阻碍一些实用特性的实现。举个例子，&lt;a href="https://opensource.com/business/15/10/lisa15-interview-alison-chaiken-mentor-graphics"&gt;systemd&lt;/a&gt; 有个叫做套接字唤醒的特性，你可以将一个守护进程设置成仅当相应的套结字被连接时才启动。这意味着你的系统可以节约内存并按需执行服务。套结字唤醒的工作原理是 systemd 代为监听 TCP 套结字，并在数据包到达套结字时启动相应的服务。一旦服务启动完毕，systemd 将套结字交给新启动的守护进程。如果将守护进程运行在基于 docker 的容器中就会出现问题。systemd 的 unit 文件通过 Docker CLI 执行容器，然而这时 systemd 却无法简单地经由 Docker CLI 将套结字转交给 Docker 守护进程。&lt;/p&gt;
&lt;p&gt;类似这样的问题让我们意识到我们需要一个运行容器的替代方案。&lt;/p&gt;
&lt;h4 id="_1"&gt;容器编排问题&lt;/h4&gt;
&lt;p&gt;上游的 docker 项目简化了容器的使用过程，同时也是一个绝佳的 Linux 容器学习工具。你可以通过一条简单的命令快速地体验如何启动一个容器，例如运行 &lt;code&gt;docker run -ti fedora sh&lt;/code&gt; 然后你就立即处于一个容器之中。&lt;/p&gt;
&lt;p&gt;当开始把许多容器组织成一个功能更为强大的应用时，你才能体会到容器真正的能力。但是问题在于伴随多容器应用而来的高复杂度使得简单的 Docker 命令无法胜任编排工作。你要如何管理容器应用在有限资源的集群节点间的布局与编排？如何管理它们的生命周期等等？&lt;/p&gt;
&lt;p&gt;在第一届 DockerCon，至少有 7 种不同的公司/开源项目展示了其容器的编排方案。红帽演示了 &lt;a href="https://www.openshift.com/"&gt;OpenShift&lt;/a&gt; 的 &lt;a href="https://openshift.github.io/geard/"&gt;geard&lt;/a&gt; 项目，它基于 OpenShift v2 的容器（叫作 gears）。红帽觉得我们需要重新审视容器编排，而且可能要与开源社区的其他人合作。&lt;/p&gt;
&lt;p&gt;Google 则演示了 Kubernetes 容器编排工具，它来源于 Google 对其自内部架构进行编排时所积累的知识经验。OpenShift 决定放弃 Gear 项目，开始和 Google 一同开发 Kubernetes。 现在 Kubernetes 是 GitHub 上最大的社区项目之一。&lt;/p&gt;
&lt;h4 id="kubernetes"&gt;Kubernetes&lt;/h4&gt;
&lt;p&gt;Kubernetes 原先被设计成使用 Google 的 &lt;a href="https://github.com/google/lmctfy"&gt;lmctfy&lt;/a&gt; 容器运行时环境来完成工作。在 2014 年夏天，lmctfy 兼容了 docker。Kubernetes 还会在 kubernetes 集群的每个节点运行一个 &lt;a href="https://kubernetes.io/docs/admin/kubelet/"&gt;kubelet&lt;/a&gt; 守护进程，这意味着原先使用 docker 1.8 的 kubernetes 工作流看起来是这样的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;kubelet → dockerdaemon @ PID1&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;回退到了双守护进程的模式。&lt;/p&gt;
&lt;p&gt;然而更糟糕的是，每次 docker 的新版本发布都使得 kubernetes 无法工作。Docker 1.10 切换镜像底层存储方案导致所有镜像重建。而 Docker 1.11 开始使用 &lt;code&gt;runc&lt;/code&gt; 来启动镜像：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;kubelet → dockerdaemon @ runc @PID1&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Docker 1.12 则增加了一个容器守护进程用于启动容器。其主要目的是为了支持 Docker Swarm （Kubernetes 的竞争者之一）：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;kubelet → dockerdaemon → containerd @runc @ pid1&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如上所述，&lt;em&gt;每一次&lt;/em&gt; docker 发布都破坏了 Kubernetes 的功能，这也是为什么 Kubernetes 和 OpenShift 请求我们为他们提供老版本 Docker 的原因。&lt;/p&gt;
&lt;p&gt;现在我们有了一个三守护进程的系统，只要任何一个出现问题，整个系统都将崩溃。&lt;/p&gt;
&lt;h3 id="_2"&gt;走向容器标准化&lt;/h3&gt;
&lt;h4 id="coreosrkt"&gt;CoreOS、rkt 和其它替代运行时&lt;/h4&gt;
&lt;p&gt;因为 docker 运行时带来的问题，几个组织都在寻求一个替代的运行时。CoreOS 就是其中之一。他们提供了一个 docker 容器运行时的替代品，叫 &lt;em&gt;rkt&lt;/em&gt; （rocket）。他们同时还引入一个标准容器规范，称作 &lt;em&gt;appc&lt;/em&gt; （App Container）。从根本上讲，他们是希望能使得所有人都使用一个标准规范来管理容器镜像中的应用。&lt;/p&gt;
&lt;p&gt;这一行为为标准化工作树立了一面旗帜。当我第一次开始和上游 docker 合作时，我最大的担忧就是最终我们会分裂出多个标准。我不希望类似 RPM 和 DEB 之间的战争影响接下来 20 年的 Linux 软件部署。appc 的一个成果是它说服了上游 docker 与开源社区合作创建了一个称作 &lt;a href="https://www.opencontainers.org/"&gt;开放容器计划（Open Container Initiative）&lt;/a&gt; (OCI) 的标准团体。&lt;/p&gt;
&lt;p&gt;OCI 已经着手制定两个规范：&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/opencontainers/runtime-spec/blob/master/spec.md"&gt;OCI 运行时规范&lt;/a&gt;：OCI 运行时规范“旨在规范容器的配置、执行环境以及生命周期”。它定义了容器的磁盘存储，描述容器内运行的应用的 JSON 文件，容器的生成和执行方式。上游 docker 贡献了 libcontainer 并构建了 runc 作为 OCI 运行时规范的默认实现。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/opencontainers/image-spec/blob/master/spec.md"&gt;OCI 镜像文件格式规范&lt;/a&gt;：镜像文件格式规范主要基于上游 docker 所使用的镜像格式，定义了容器仓库中实际存储的容器镜像格式。该规范使得应用开发者能为应用使用单一的标准化格式。一些 appc 中描述的概念被加入到 OCI 镜像格式规范中得以保留。这两份规范 1.0 版本的发布已经临近（LCTT 译注：&lt;a href="https://linux.cn/article-8778-1.html"&gt;已经发布&lt;/a&gt;）。上游 docker 已经同意在 OCI 镜像规范定案后支持该规范。Rkt 现在既支持运行 OCI 镜像也支持传统的上游 docker 镜像。&lt;/p&gt;
&lt;p&gt;OCI 通过为工业界提供容器镜像与运行时标准化的环境，帮助在工具与编排领域解放创新的力量。&lt;/p&gt;
&lt;h4 id="_3"&gt;抽象运行时接口&lt;/h4&gt;
&lt;p&gt;得益于标准化工作， Kubernetes 编排领域也有所创新。作为 Kubernetes 的一大支持者，CoreOS 提交了一堆补丁，使 Kubernetes 除了 docker 引擎外还能通过 rkt 运行容器并且与容器通讯。Google 和 Kubernetes 上游预见到增加这些补丁和将来可能添加的容器运行时接口将给 Kubernetes 带来的代码复杂度，他们决定实现一个叫作 容器运行时接口（Container Runtime Interface） (CRI) 的 API 协议规范。于是他们将 Kubernetes 由原来的直接调用 docker 引擎改为调用 CRI，这样任何人都可以通过实现服务器端的 CRI 来创建支持
Kubernetes 的容器运行时。Kubernetes 上游还为 CRI 开发者们创建了一个大型测试集以验证他们的运行时对 Kubernetes 的支持情况。开发者们还在努力地移除 Kubernetes 对 docker 引擎的调用并将它们隐藏在一个叫作 docker-shim 的薄抽象层后。&lt;/p&gt;
&lt;h3 id="_4"&gt;容器工具的创新&lt;/h3&gt;
&lt;h4 id="skopeo"&gt;伴随 skopeo 而来的容器仓库创新&lt;/h4&gt;
&lt;p&gt;几年前我们正与 Atomic 项目团队合作构建 &lt;a href="https://github.com/projectatomic/atomic"&gt;atomic CLI&lt;/a&gt;。我们希望实现一个功能，在镜像还在镜像仓库时查看它的细节。在那时，查看仓库中的容器镜像相关 JSON 文件的唯一方法是将镜像拉取到本地服务器再通过 &lt;code&gt;docker inspect&lt;/code&gt; 来查看 JSON 文件。这些镜像可能会很大，上至几个 GiB。为了允许用户在不拉取镜像的情况下查看镜像细节，我们希望在 &lt;code&gt;docker inspect&lt;/code&gt; 接口添加新的 &lt;code&gt;--remote&lt;/code&gt; 参数。上游 docker 拒绝了我们的代码拉取请求（PR），告知我们他们不希望将 Docker CLI 复杂化，我们可以构建我们自己的工具去实现相同的功能。&lt;/p&gt;
&lt;p&gt;我们的团队在 &lt;a href="https://twitter.com/runc0m"&gt;Antonio Murdaca&lt;/a&gt; 的领导下执行这个提议，构建了 &lt;a href="https://github.com/projectatomic/skopeo"&gt;skopeo&lt;/a&gt;。Antonio 没有止步于拉取镜像相关的 JSON 文件，而是决定实现一个完整的协议，用于在容器仓库与本地主机之间拉取与推送容器镜像。&lt;/p&gt;
&lt;p&gt;skopeo 现在被 atomic CLI 大量用于类似检查容器更新的功能以及 &lt;a href="https://developers.redhat.com/blog/2016/05/02/introducing-atomic-scan-container-vulnerability-detection/"&gt;atomic 扫描&lt;/a&gt; 当中。Atomic 也使用 skopeo 取代上游 docker 守护进程拉取和推送镜像的功能。&lt;/p&gt;
&lt;h4 id="containersimage"&gt;Containers/image&lt;/h4&gt;
&lt;p&gt;我们也曾和 CoreOS 讨论过在 rkt 中使用 skopeo 的可能，然而他们表示不希望运行一个外部的协助程序，但是会考虑使用 skopeo 所使用的代码库。于是我们决定将 skopeo 分离为一个代码库和一个可执行程序，创建了 &lt;a href="https://github.com/containers/image"&gt;image&lt;/a&gt; 代码库。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/containers/image"&gt;containers/images&lt;/a&gt; 代码库和 skopeo 被几个其它上游项目和云基础设施工具所使用。Skopeo 和 containers/image 已经支持 docker 和多个存储后端，而且能够在容器仓库之间移动容器镜像，还拥有许多酷炫的特性。&lt;a href="http://rhelblog.redhat.com/2017/05/11/skopeo-copy-to-the-rescue/"&gt;skopeo 的一个优点&lt;/a&gt;是它不需要任何守护进程的协助来完成任务。Containers/image 代码库的诞生使得类似&lt;a href="https://access.redhat.com/articles/2750891"&gt;容器镜像签名&lt;/a&gt;等增强功能得以实现。&lt;/p&gt;
&lt;h4 id="_5"&gt;镜像处理与扫描的创新&lt;/h4&gt;
&lt;p&gt;我在前文提到 atomic CLI。我们构建这个工具是为了给容器添加不适合 docker CLI 或者我们无法在上游 docker 中实现的特性。我们也希望获得足够灵活性，将其用于开发额外的容器运行时、工具和存储系统。Skopeo 就是一例。&lt;/p&gt;
&lt;p&gt;我们想要在 atomic 实现的一个功能是 &lt;code&gt;atomic mount&lt;/code&gt;。从根本上讲，我们希望从 Docker 镜像存储（上游 docker 称之为 graph driver）中获取内容，把镜像挂在到某处，以便用工具来查看该镜像。如果你使用上游的 docker，查看镜像内容的唯一方法就是启动该容器。如果其中有不可信的内容，执行容器中的代码来查看它会有潜在危险。通过启动容器查看镜像内容的另一个问题是所需的工具可能没有被包含在容器镜像当中。&lt;/p&gt;
&lt;p&gt;大多数容器镜像扫描器遵循以下流程：它们连接到 Docker 的套结字，执行一个 &lt;code&gt;docker save&lt;/code&gt; 来创建一个 tar 打包文件，然后在磁盘上分解这个打包文件，最后查看其中的内容。这是一个很慢的过程。&lt;/p&gt;
&lt;p&gt;通过 &lt;code&gt;atomic mount&lt;/code&gt;，我们希望直接使用 Docker graph driver 挂载镜像。如果 docker 守护进程使用 device mapper，我们将挂载这个设备。如果它使用 overlay，我们会挂载 overlay。这个操作很快而且满足我们的需求。现在你可以执行：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# atomic mount fedora /mnt
# cd /mnt
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;然后开始探查内容。你完成相应工作后，执行：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# atomic umount /mnt
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;我们在 &lt;code&gt;atomic scan&lt;/code&gt; 中使用了这一特性，实现了一个快速的容器扫描器。&lt;/p&gt;
&lt;h4 id="_6"&gt;工具协作的问题&lt;/h4&gt;
&lt;p&gt;其中一个严重的问题是 &lt;code&gt;atomic mount&lt;/code&gt; 隐式地执行这些工作。Docker 守护进程不知道有另一个进程在使用这个镜像。这会导致一些问题（例如，如果你先挂载了 Fedora 镜像，然后某个人执行了 &lt;code&gt;docker rmi fedora&lt;/code&gt; 命令，docker 守护进程移除镜像时就会产生奇怪的操作失败，同时报告说相应的资源忙碌）。Docker 守护进程可能因此进入一个奇怪的状态。&lt;/p&gt;
&lt;h4 id="_7"&gt;容器存储系统&lt;/h4&gt;
&lt;p&gt;为了解决这个问题，我们开始尝试将从上游 docker 守护进程剥离出来的 graph driver 代码拉取到我们的代码库中。Docker 守护进程在内存中为 graph driver 完成所有锁的获取。我们想要将这些锁操作转移到文件系统中，这样我们可以支持多个不同的进程来同时操作容器的存储系统，而不用通过单一的守护进程。&lt;/p&gt;
&lt;p&gt;我们创建了 &lt;a href="https://github.com/containers/storage"&gt;containers/storage&lt;/a&gt; 项目，实现了容器运行、构建、存储所需的所有写时拷贝（COW）特性，同时不再需要一个单一进程来控制和监控这个过程（也就是不需要守护进程）。现在 skopeo 以及其它工具和项目可以直接利用镜像的存储系统。其它开源项目也开始使用 containers/storage，在某些时候，我们也会把这些项目合并回上游 docker 项目。&lt;/p&gt;
&lt;h3 id="_8"&gt;驶向创新&lt;/h3&gt;
&lt;p&gt;当 Kubernetes 在一个节点上使用 docker 守护进程运行容器时会发生什么？首先，Kubernetes 执行一条类似如下的命令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;kubelet run nginx -image=nginx
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个命令告诉 kubelet 在节点上运行 NGINX 应用程序。kubelet 调用 CRI 请求启动 NGINX 应用程序。在这时，实现了 CRI 规范的容器运行时必须执行以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;检查本地是否存在名为 &lt;code&gt;nginx&lt;/code&gt; 的容器。如果没有，容器运行时会在容器仓库中搜索标准的容器镜像。&lt;/li&gt;
&lt;li&gt;如果镜像不存在于本地，从容器仓库下载到本地系统。&lt;/li&gt;
&lt;li&gt;使用容器存储系统（通常是写时拷贝存储系统）解析下载的容器镜像并挂载它。&lt;/li&gt;
&lt;li&gt;使用标准的容器运行时执行容器。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;让我们看看上述过程使用到的特性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;OCI 镜像格式规范定义了容器仓库存储的标准镜像格式。&lt;/li&gt;
&lt;li&gt;Containers/image 代码库实现了从容器仓库拉取镜像到容器主机所需的所有特性。&lt;/li&gt;
&lt;li&gt;Containers/storage 提供了在写时拷贝的存储系统上探查并处理 OCI 镜像格式的代码库。&lt;/li&gt;
&lt;li&gt;OCI 运行时规范以及 &lt;code&gt;runc&lt;/code&gt; 提供了执行容器的工具（同时也是 docker 守护进程用来运行容器的工具）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这意味着我们可以利用这些工具来使用容器，而无需一个大型的容器守护进程。&lt;/p&gt;
&lt;p&gt;在中等到大规模的基于 DevOps 的持续集成/持续交付环境下，效率、速度和安全性至关重要。只要你的工具遵循 OCI 规范，开发者和执行者就能在持续集成、持续交付到生产环境的自动化中自然地使用最佳的工具。大多数的容器工具被隐藏在容器编排或上层容器平台技术之下。我们预想着有朝一日，运行时和镜像工具的选择会变成容器平台的一个安装选项。&lt;/p&gt;
&lt;h4 id="_9"&gt;系统（独立）容器&lt;/h4&gt;
&lt;p&gt;在 Atomic 项目中我们引入了&lt;ruby&gt;原子主机&lt;rt&gt;atomic host&lt;/rt&gt;&lt;/ruby&gt;，一种新的操作系统构建方式：所有的软件可以被“原子地”升级并且大多数应用以容器的形式运行在操作系统中。这个平台的目的是证明将来所有的软件都能部署在 OCI 镜像格式中并且使用标准协议从容器仓库中拉取，然后安装到系统上。用容器镜像的形式发布软件允许你以不同的速度升级应用程序和操作系统。传统的 RPM/yum/DNF 包分发方式把应用更新锁定在操作系统的生命周期中。&lt;/p&gt;
&lt;p&gt;在以容器部署基础设施时多数会遇到一个问题——有时一些应用必须在容器运行时执行之前启动。我们看一个使用 docker 的 Kubernetes 的例子：Kubernetes 为了将 pods 或者容器部署在独立的网络中，要求先建立一个网络。现在默认用于创建网络的守护进程是 &lt;a href="https://github.com/coreos/flannel"&gt;flanneld&lt;/a&gt;，而它必须在 docker 守护进程之前启动，以支持 docker 网络接口来运行 Kubernetes 的 pods。而且，flanneld 使用 &lt;a href="https://github.com/coreos/etcd"&gt;etcd&lt;/a&gt; 来存储数据，这个守护进程必须在 flanneld 启动之前运行。&lt;/p&gt;
&lt;p&gt;如果你想把 etcd 和 flanneld 部署到容器镜像中，那就陷入了鸡与鸡蛋的困境中。我们需要容器运行时来启动容器化的应用，但这些应用又需要在容器运行时之前启动。我见过几个取巧的方法尝试解决这个问题，但这些方法都不太干净利落。而且 docker 守护进程当前没有合适的方法来配置容器启动的优先级顺序。我见过一些提议，但它们看起来和 SysVInit 所使用的启动服务的方式相似（我们知道它带来的复杂度）。&lt;/p&gt;
&lt;h4 id="systemd"&gt;systemd&lt;/h4&gt;
&lt;p&gt;用 systemd 替代 SysVInit 的原因之一就是为了处理服务启动的优先级和顺序，我们为什么不充分利用这种技术呢？在 Atomic 项目中我们决定在让它在没有容器运行时的情况下也能启动容器，尤其是在系统启动早期。我们增强了 atomic CLI 的功能，让用户可以安装容器镜像。当你执行 &lt;code&gt;atomic install --system etc&lt;/code&gt;，它将利用 skopeo 从外部的容器仓库拉取 etcd 的 OCI 镜像，然后把它分解（扩展）为 OSTree 底层存储。因为 etcd 运行在生产环境中，我们把镜像处理为只读。接着 &lt;code&gt;atomic&lt;/code&gt; 命令抓取容器镜像中的 systemd 的 unit 文件模板，用它在磁盘上创建 unit 文件来启动镜像。这个 unit 文件实际上使用 &lt;code&gt;runc&lt;/code&gt; 来在主机上启动容器（虽然 &lt;code&gt;runc&lt;/code&gt; 不是必需的）。&lt;/p&gt;
&lt;p&gt;执行 &lt;code&gt;atomic install --system flanneld&lt;/code&gt; 时会进行相似的过程，但是这时 flanneld 的 unit 文件中会指明它依赖 etcd。&lt;/p&gt;
&lt;p&gt;在系统引导时，systemd 会保证 etcd 先于 flanneld 运行，并且直到 flanneld 启动完毕后再启动容器运行时。这样我们就能把 docker 守护进程和 Kubernetes 部署到系统容器当中。这也意味着你可以启动一台原子主机或者使用传统的基于 rpm 的操作系统，让整个容器编排工具栈运行在容器中。这是一个强大的特性，因为用户往往希望改动容器主机时不受这些组件影响。而且，它保持了主机的操作系统的占用最小化。&lt;/p&gt;
&lt;p&gt;大家甚至讨论把传统的应用程序部署到独立/系统容器或者被编排的容器中。设想一下，可以用 &lt;code&gt;atomic install --system httpd&lt;/code&gt; 命令安装一个 Apache 容器，这个容器可以和用 RPM 安装的 httpd 服务以相同的方式启动（&lt;code&gt;systemctl start httpd&lt;/code&gt; ，区别是这个容器 httpd 运行在一个容器中）。存储系统可以是本地的，换言之，&lt;code&gt;/var/www&lt;/code&gt; 是从宿主机挂载到容器当中的，而容器监听着本地网络的 80 端口。这表明了我们可以在不使用容器守护进程的情况下将传统的负载组件部署到一个容器中。&lt;/p&gt;
&lt;h3 id="_10"&gt;构建容器镜像&lt;/h3&gt;
&lt;p&gt;在我看来，在过去 4 年来容器发展方面最让人失落的是缺少容器镜像构建机制上的创新。容器镜像不过是将一些 tar 包文件与 JSON 文件一起打包形成的文件。基础镜像则是一个 rootfs 与一个描述该基础镜像的 JSON 文件。然后当你增加镜像层时，层与层之间的差异会被打包，同时 JSON 文件会做出相应修改。这些镜像层与基础文件一起被打包，共同构成一个容器镜像。&lt;/p&gt;
&lt;p&gt;现在几乎所有人都使用 &lt;code&gt;docker build&lt;/code&gt; 与 Dockerfile 格式来构建镜像。上游 docker 已经在几年前停止了接受修改或改进 Dockerfile 格式的拉取请求（PR）了。Dockerfile 在容器的演进过程中扮演了重要角色，开发者和管理员/运维人员可以通过简单直接的方式来构建镜像；然而我觉得 Dockerfile 就像一个简陋的 bash 脚本，还带来了一些尚未解决的问题，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 Dockerfile 创建容器镜像要求运行着 Docker 守护进程。&lt;ul&gt;
&lt;li&gt;没有可以独立于 docker 命令的标准工具用于创建 OCI 镜像。&lt;/li&gt;
&lt;li&gt;甚至类似 &lt;code&gt;ansible-containers&lt;/code&gt; 和 OpenShift S2I (Source2Image) 的工具也在底层使用 &lt;code&gt;docker-engine&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dockerfile 中的每一行都会创建一个新的镜像，这有助于创建容器的开发过程，这是因为构建工具能够识别 Dockerfile 中的未改动行，复用已经存在的镜像从而避免了未改动行的重复执行。但这个特性会产生_大量_的镜像层。&lt;ul&gt;
&lt;li&gt;因此，不少人希望构建机制能压制镜像消除这些镜像层。我猜想上游 docker 最后应该接受了一些提交满足了这个需求。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;要从受保护的站点拉取内容到容器镜像，你往往需要某种密钥。比如你为了添加 RHEL 的内容到镜像中，就需要访问 RHEL 的证书和订阅。&lt;ul&gt;
&lt;li&gt;这些密钥最终会被以层的方式保存在镜像中。开发者要费很大工夫去移除它们。&lt;/li&gt;
&lt;li&gt;为了允许在 docker 构建过程中挂载数据卷，我们在我们维护的 projectatomic/docker 中加入了 &lt;code&gt;-v volume&lt;/code&gt; 选项，但是这些修改没有被上游 docker 接受。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;构建过程的中间产物最终会保留在容器镜像中，所以尽管 Dockerfile 易于学习，当你想要了解你要构建的镜像时甚至可以在笔记本上构建容器，但它在大规模企业环境下还不够高效。然而在自动化容器平台下，你应该不会关心用于构建 OCI 镜像的方式是否高效。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="buildah"&gt;Buildah 起航&lt;/h3&gt;
&lt;p&gt;在 DevConf.cz 2017，我让我们团队的 &lt;a href="https://twitter.com/nalind"&gt;Nalin Dahyabhai&lt;/a&gt; 考虑构建被我称为 &lt;code&gt;containers-coreutils&lt;/code&gt; 的工具，它基本上就是基于 containers/storage 和 containers/image 库构建的一系列可以使用类似 Dockerfile 语法的命令行工具。Nalin 为了取笑我的波士顿口音，决定把它叫做 &lt;a href="https://github.com/projectatomic/buildah"&gt;buildah&lt;/a&gt;。我们只需要少量的 buildah 原语就可以构建一个容器镜像：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最小化 OS 镜像、消除不必要的工具是主要的安全原则之一。因为黑客在攻击应用时需要一些工具，如果类似 &lt;code&gt;gcc&lt;/code&gt;，&lt;code&gt;make&lt;/code&gt;，&lt;code&gt;dnf&lt;/code&gt; 这样的工具根本不存在，就能阻碍攻击者的行动。&lt;/li&gt;
&lt;li&gt;减小容器的体积总是有益的，因为这些镜像会通过互联网拉取与推送。&lt;/li&gt;
&lt;li&gt;使用 Docker 进行构建的基本原理是在容器构建的根目录下利用命令安装或编译软件。&lt;/li&gt;
&lt;li&gt;执行 &lt;code&gt;run&lt;/code&gt; 命令要求所有的可执行文件都包含在容器镜像内。只是在容器镜像中使用 &lt;code&gt;dnf&lt;/code&gt; 就需要完整的 Python 栈，即使在应用中从未使用到 Python。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ctr=$(buildah from fedora)&lt;/code&gt;:&lt;ul&gt;
&lt;li&gt;使用 containers/image 从容器仓库拉取 Fedora 镜像。&lt;/li&gt;
&lt;li&gt;返回一个容器 ID （&lt;code&gt;ctr&lt;/code&gt;）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mnt=$(buildah mount $ctr)&lt;/code&gt;:&lt;ul&gt;
&lt;li&gt;挂载新建的容器镜像（&lt;code&gt;$ctr&lt;/code&gt;）.&lt;/li&gt;
&lt;li&gt;返回挂载点路径。&lt;/li&gt;
&lt;li&gt;现在你可以使用挂载点来写入内容。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dnf install httpd –installroot=$mnt&lt;/code&gt;:&lt;ul&gt;
&lt;li&gt;你可以使用主机上的命令把内容重定向到容器中，这样你可以把密钥保留在主机而不导入到容器内，同时构建所用的工具也仅仅存在于主机上。&lt;/li&gt;
&lt;li&gt;容器内不需要包含 &lt;code&gt;dnf&lt;/code&gt; 或者 Python 栈，除非你的应用用到它们。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cp foobar $mnt/dir&lt;/code&gt;:&lt;ul&gt;
&lt;li&gt;你可以使用任何 bash 中可用的命令来构造镜像。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;buildah commit $ctr&lt;/code&gt;:&lt;ul&gt;
&lt;li&gt;你可以随时创建一个镜像层，镜像的分层由用户而不是工具来决定。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;buildah config --env container=oci --entrypoint /usr/bin/httpd $ctr&lt;/code&gt;:&lt;ul&gt;
&lt;li&gt;Buildah 支持所有 Dockerfile 的命令。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;buildah run $ctr dnf -y install httpd&lt;/code&gt;:&lt;ul&gt;
&lt;li&gt;Buildah 支持 &lt;code&gt;run&lt;/code&gt; 命令，但它是在一个锁定的容器内利用 &lt;code&gt;runc&lt;/code&gt; 执行命令，而不依赖容器运行时守护进程。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;buildah build-using-dockerfile -f Dockerfile .&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;我们希望将移植类似 &lt;code&gt;ansible-containers&lt;/code&gt; 和 OpenShift S2I 这样的工具，改用 &lt;code&gt;buildah&lt;/code&gt; 以去除对容器运行时守护进程的依赖。&lt;/p&gt;
&lt;p&gt;使用与生产环境相同的容器运行时构建容器镜像会遇到另一个大问题。为了保证安全性，我们需要把权限限制到支持容器构建与运行所需的最小权限。构建容器比起运行容器往往需要更多额外的权限。举个例子，我们默认允许 &lt;code&gt;mknod&lt;/code&gt; 权限，这会允许进程创建设备节点。有些包的安装会尝试创建设备节点，然而在生产环境中的应用几乎都不会这么做。如果默认移除生产环境中容器的 &lt;code&gt;mknod&lt;/code&gt; 特权会让系统更为安全。&lt;/p&gt;
&lt;p&gt;另一个例子是，容器镜像默认是可读写的，因为安装过程意味着向 &lt;code&gt;/usr&lt;/code&gt; 存入软件包。然而在生产环境中，我强烈建议把所有容器设为只读模式，仅仅允许它们写入 tmpfs 或者是挂载了数据卷的目录。通过分离容器的构建与运行环境，我们可以更改这些默认设置，提供一个更为安全的环境。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当然，buildah 可以使用 Dockerfile 构建容器镜像。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="cri-o-kubernetes"&gt;CRI-O ：一个 Kubernetes 的运行时抽象&lt;/h3&gt;
&lt;p&gt;Kubernetes 添加了&lt;ruby&gt;容器运行时接口&lt;rt&gt;Container Runtime Interface&lt;/rt&gt;&lt;/ruby&gt;（CRI）接口，使 pod 可以在任何运行时上工作。虽然我不是很喜欢在我的系统上运行太多的守护进程，然而我们还是加了一个。我的团队在 &lt;a href="https://twitter.com/mrunalp"&gt;Mrunal Patel&lt;/a&gt; 的领导下于 2016 年后期开始构建 [CRI-O] 守护进程。这是一个用来运行 OCI 应用程序的 OCI 守护进程。理论上，将来我们能够把 CRI-O 的代码直接并入 kubelet 中从而消除这个多余的守护进程。&lt;/p&gt;
&lt;p&gt;不像其它容器运行时，CRI-O 的唯一目的就只是为了满足 Kubernetes 的需求。记得前文描述的 Kubernetes 运行容器的条件。&lt;/p&gt;
&lt;p&gt;Kubernetes 传递消息给 kubelet 告知其运行 NGINX 服务器：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;kubelet 唤醒 CRI-O 并告知它运行 NGINX。&lt;/li&gt;
&lt;li&gt;CRI-O 回应 CRI 请求。&lt;/li&gt;
&lt;li&gt;CRI-O 在容器仓库查找 OCI 镜像。&lt;/li&gt;
&lt;li&gt;CRI-O 使用 containers/image 从仓库拉取镜像到主机。&lt;/li&gt;
&lt;li&gt;CRI-O 使用 containers/storage 解压镜像到本地磁盘。&lt;/li&gt;
&lt;li&gt;CRI-O 按照 OCI 运行时规范（通常使用 &lt;code&gt;runc&lt;/code&gt;）启动容器。如前文所述，Docker 守护进程也同样使用 &lt;code&gt;runc&lt;/code&gt; 启动它的容器。&lt;/li&gt;
&lt;li&gt;按照需要，kubelet 也可以使用替代的运行时启动容器，例如 Clear Containers &lt;code&gt;runcv&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;CRI-O 旨在成为稳定的 Kubernetes 运行平台。只有通过完整的 Kubernetes 测试集后，新版本的 CRI-O 才会被推出。所有提交到 &lt;a href="https://github.com/Kubernetes-incubator/cri-o"&gt;https://github.com/Kubernetes-incubator/cri-o&lt;/a&gt; 的拉取请求都会运行完整的 Kubernetes 测试集。没有通过测试集的拉取请求都不会被接受。CRI-O 是完全开放的，我们已经收到了来自 Intel、SUSE、IBM、Google、Hyper.sh 等公司的代码贡献。即使不是红帽想要的特性，只要通过一定数量维护者的同意，提交给 CRI-O 的补丁就会被接受。&lt;/p&gt;
&lt;h3 id="_11"&gt;小结&lt;/h3&gt;
&lt;p&gt;我希望这份深入的介绍能够帮助你理解 Linux 容器的演化过程。Linux 容器曾经陷入一种各自为营的困境，Docker 建立起了镜像创建的事实标准，简化了容器的使用工具。OCI 则意味着业界在核心镜像格式与运行时方面的合作，这促进了工具在自动化效率、安全性、高可扩展性、易用性方面的创新。容器使我们能够以一种新奇的方式部署软件——无论是运行于主机上的传统应用还是部署在云端的微服务。而在许多方面，这一切还仅仅是个开始。&lt;/p&gt;
&lt;p&gt;（题图：&lt;a href="https://www.flickr.com/photos/danramarch/"&gt;Daniel Ramirez&lt;/a&gt; &lt;a href="https://creativecommons.org/licenses/by-sa/4.0/"&gt;CC BY-SA 4.0&lt;/a&gt;）&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;作者简介：&lt;/p&gt;
&lt;p&gt;Daniel J Walsh - Daniel 有将近 30 年的计算机安全领域工作经验。他在 2001 年 8 月加入 Red Hat。&lt;/p&gt;</content><category term="container"></category><category term="docker"></category><category term="linux"></category><category term="翻译"></category></entry></feed>